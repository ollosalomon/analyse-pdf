# Documentation du projet



# ðŸ“˜ RAG PDF Analyzer

Ce projet permet de traiter des fichiers PDF volumineux (jusquâ€™Ã  2000 pages), dâ€™en extraire le contenu textuel et visuel, de les vectoriser, puis de gÃ©nÃ©rer automatiquement un rapport analytique structurÃ© Ã  lâ€™aide dâ€™un LLM (comme Gemini).

## ðŸ§± FonctionnalitÃ©s

- Extraction par lots (batch) de texte et dâ€™images depuis un PDF
- Indexation vectorielle (ChromaDB + embeddings GPT4All)
- Analyse de structure du document (chapitres/sections)
- GÃ©nÃ©ration de rapport synthÃ©tique via Gemini (Google Generative AI)
- Interface Streamlit conviviale
- Ligne de commande alternative

## ðŸš€ DÃ©marrage rapide

```bash
# 1. Cloner et configurer lâ€™environnement
cp .env.example .env  # ou Ã©diter .env
pip install -r requirements.txt

# 2. Lancer lâ€™interface web
streamlit run app/interface/streamlit_app.py

# 3. Ou utiliser le CLI
python app/main.py --help
```


rag_pdf_analyzer/
â”‚
â”œâ”€â”€ app/                        # Code principal de l'application
â”‚   â”œâ”€â”€ __init__.py             # Rend le package importable
â”‚   â”œâ”€â”€ config.py               # Chargement des variables d'environnement (.env)
â”‚   â”œâ”€â”€ main.py                 # Point d'entrÃ©e global (redirige vers CLI ou web)
â”‚
â”‚   â”œâ”€â”€ ingestion/              # Ã‰tape d'extraction et de prÃ©traitement
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py       # DÃ©coupe du PDF par lots (batchs de pages)
â”‚   â”‚   â”œâ”€â”€ image_extractor.py  # Extraction et description des images de chaque page
â”‚   â”‚   â”œâ”€â”€ chunker.py          # DÃ©coupe des textes en chunks hiÃ©rarchiques (chapitres/sections)
â”‚   â”‚   â””â”€â”€ structure_parser.py # DÃ©tection des chapitres/sections via regex
â”‚
â”‚   â”œâ”€â”€ vectorstore/            # Indexation et recherche vectorielle
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embeddings.py       # Chargement du modÃ¨le d'embeddings (GPT4All ou autre)
â”‚   â”‚   â”œâ”€â”€ chroma_db.py        # Gestion de la base Chroma + mÃ©tadonnÃ©es
â”‚   â”‚   â””â”€â”€ vector_utils.py     # Fonctions utilitaires de recherche (filtrÃ©e, par chapitre, etc.)
â”‚
â”‚   â”œâ”€â”€ report/                 # GÃ©nÃ©ration de rapports LLM
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ generator.py        # GÃ©nÃ©rateur avec mÃ©moire de contexte (structure + rÃ©sumÃ©s)
â”‚   â”‚   â””â”€â”€ prompts.py          # Prompts LLM structurÃ©s (extraction de plan, rÃ©sumÃ©, synthÃ¨se finale)
â”‚
â”‚   â””â”€â”€ interface/              # Interfaces utilisateur (CLI et Web)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ streamlit_app.py    # Application Streamlit pour visualisation et rapport
â”‚       â””â”€â”€ cli.py              # Interface ligne de commande avec argparse
â”‚
â”œâ”€â”€ output/                     # DonnÃ©es gÃ©nÃ©rÃ©es automatiquement
â”‚   â”œâ”€â”€ extracted_text/         # Fichiers texte extraits du PDF
â”‚   â”œâ”€â”€ extracted_images/       # Images extraites et annotÃ©es par Gemini
â”‚   â”œâ”€â”€ vector_db/              # Chunks vectorisÃ©s persistÃ©s via Chroma
â”‚   â””â”€â”€ metadata/               # Statistiques de traitement, Ã©tat dâ€™avancement, logs
â”‚
â”œâ”€â”€ tests/                      # Tests unitaires automatisÃ©s
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_loader.py          # Test de lecture PDF et batch
â”‚   â”œâ”€â”€ test_chunking.py        # Test de la structure hiÃ©rarchique et des chunks
â”‚   â””â”€â”€ test_generation.py      # Test du gÃ©nÃ©rateur de rapport
â”‚
â”œâ”€â”€ .env                        # Variables sensibles (clÃ© API Gemini, chemins, etc.)
â”œâ”€â”€ requirements.txt            # Toutes les dÃ©pendances Python requises
â”œâ”€â”€ README.md                   # Ce fichier de documentation
â””â”€â”€ setup.py                    # Rend le projet installable en tant que module Python
